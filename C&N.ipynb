{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7957a2b",
   "metadata": {},
   "source": [
    "# **Cleaning & Normalization**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b8de5f",
   "metadata": {},
   "source": [
    "#### _We import the libraries we will use and additional configuration_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a84194cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- Configuration ---\n",
    "INPUT_FILE = \"ventas.csv\"\n",
    "OUTPUT_FOLDER = \"cleaned_seeders\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ce22ab",
   "metadata": {},
   "source": [
    "## **_1. Setup and file loading_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "644f81b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Data Processing for: ventas.csv ---\n",
      "Loading file: ventas.csv\n",
      "File loaded and column names cleaned.\n"
     ]
    }
   ],
   "source": [
    "print(f\"--- Starting Data Processing for: {INPUT_FILE} ---\")\n",
    "\n",
    "try:\n",
    "    # Create output folder if it doesn't exist\n",
    "    if not os.path.exists(OUTPUT_FOLDER):\n",
    "        os.makedirs(OUTPUT_FOLDER)\n",
    "        print(f\"Output Folder '{OUTPUT_FOLDER}' created.\")\n",
    "        \n",
    "    print(f\"Loading file: {INPUT_FILE}\")\n",
    "    df = pd.read_csv(INPUT_FILE)\n",
    "    \n",
    "    # Clean column names (replace spaces with underscores)\n",
    "    df.columns = [col.replace(' ', '_') for col in df.columns]\n",
    "    \n",
    "    print(\"File loaded and column names cleaned.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during file loading: {e}\")\n",
    "    # Exit on other critical errors\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096491d2",
   "metadata": {},
   "source": [
    "## **_2. Data cleaning_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "421fc7ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Phase 1: Data Cleaning...\n",
      "  Removed 4068 duplicate rows.\n",
      "  Text columns cleaned and normalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alber\\AppData\\Local\\Temp\\ipykernel_16496\\2827889152.py:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(0, inplace=True)\n",
      "C:\\Users\\alber\\AppData\\Local\\Temp\\ipykernel_16496\\2827889152.py:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(0, inplace=True)\n",
      "C:\\Users\\alber\\AppData\\Local\\Temp\\ipykernel_16496\\2827889152.py:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(0, inplace=True)\n",
      "C:\\Users\\alber\\AppData\\Local\\Temp\\ipykernel_16496\\2827889152.py:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(0, inplace=True)\n",
      "C:\\Users\\alber\\AppData\\Local\\Temp\\ipykernel_16496\\2827889152.py:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(0, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Numeric columns cleaned and standardized.\n",
      "  Date column validated and missing values filled.\n",
      "Data Cleaning completed successfully.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(\"Starting Phase 1: Data Cleaning...\")\n",
    "\n",
    "    # 1. Remove duplicates\n",
    "    rows_before = len(df)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    print(f\"  Removed {rows_before - len(df)} duplicate rows.\")\n",
    "\n",
    "    # 2. Clean Text Columns\n",
    "    string_columns = ['Ciudad', 'Producto', 'Tipo_Producto', 'Tipo_Venta', 'Tipo_Cliente']\n",
    "    \n",
    "    for col in string_columns:\n",
    "        # Normalization (Uppercase, strip spaces, remove accents/special chars)\n",
    "        df[col] = df[col].astype(str).str.upper().str.strip()\n",
    "        df[col] = df[col].str.replace('Á', 'A').str.replace('É', 'E').str.replace('Í', 'I').str.replace('Ó', 'O').str.replace('Ú', 'U').str.replace('[^A-Z0-9_ ]', '', regex=True)\n",
    "    print(\"  Text columns cleaned and normalized.\")\n",
    "\n",
    "    # 3. Clean Numeric Columns\n",
    "    numeric_columns = ['Cantidad', 'Precio_Unitario', 'Descuento', 'Costo_Envio', 'Total']\n",
    "\n",
    "    for col in numeric_columns:\n",
    "        # Handle decimal separators and convert to numeric\n",
    "        df[col] = df[col].astype(str).str.replace(',', '.', regex=False)\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce') # Coerce non-numeric to NaN\n",
    "        \n",
    "        # Fill NaN with 0\n",
    "        df[col].fillna(0, inplace=True)\n",
    "        \n",
    "        # Handle negative values for Quantity/Unit Price\n",
    "        if col in ['Cantidad', 'Precio_Unitario']:\n",
    "             df.loc[df[col] < 0, col] = df[col].abs()\n",
    "             \n",
    "    print(\"  Numeric columns cleaned and standardized.\")\n",
    "\n",
    "    # 4. Clean Date Column\n",
    "    df['Fecha'] = pd.to_datetime(df['Fecha'], errors='coerce')\n",
    "    print(\"  Date column validated and missing values filled.\")\n",
    "\n",
    "    print(\"Data Cleaning completed successfully.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during the Data Cleaning phase: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7da58e5",
   "metadata": {},
   "source": [
    "## **_3. Normalization and seeder generation_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cbb3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalization and Seeder Generation...\n",
      "  Generating seeder: DimCiudad\n",
      "  Generating seeder: DimProducto\n",
      "  Generating seeder: DimTipo_Venta\n",
      "  Generating seeder: DimTipo_Cliente\n",
      "\n",
      "  Generating seeder: FactSales\n",
      "  Saved: cleaned_seeders\\seeder_FactVentas.csv with 1245932 rows.\n",
      "\n",
      "Phase 2: Normalization and Seeder Generation completed successfully.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(\"Normalization and Seeder Generation...\")\n",
    "\n",
    "    # Define dimension tables\n",
    "    dimension_tables = {\n",
    "        \"Ciudad\": [\"Ciudad\"],\n",
    "        \"Producto\": [\"Producto\"], \n",
    "        \"Tipo_Venta\": [\"Tipo_Venta\"],\n",
    "        \"Tipo_Cliente\": [\"Tipo_Cliente\"]\n",
    "    }\n",
    "\n",
    "    dimension_dfs = {}\n",
    "    join_columns = []\n",
    "\n",
    "    # Generate Dimension Tables (Dim)\n",
    "    for table, columns in dimension_tables.items():\n",
    "        table_name = f\"Dim{table}\"\n",
    "        id_col = f\"ID_{table}\" \n",
    "        \n",
    "        print(f\"  Generating seeder: {table_name}\")\n",
    "        \n",
    "        # Create dimension table\n",
    "        df_dim = df[columns].drop_duplicates().reset_index(drop=True)\n",
    "        df_dim.insert(0, id_col, df_dim.index + 1)\n",
    "        \n",
    "        # Save Dimension Table\n",
    "        output_filename = os.path.join(OUTPUT_FOLDER, f\"seeder_{table_name}.csv\")\n",
    "        df_dim.to_csv(output_filename, index=False)\n",
    "        \n",
    "        dimension_dfs[table] = df_dim\n",
    "        join_columns.extend(columns) \n",
    "\n",
    "    # Generate Sales Fact Table (FactSales)\n",
    "    print(\"\\n  Generating seeder: FactVentas\")\n",
    "\n",
    "    # Metrics and non dimension attributes for the Fact table\n",
    "    sales_attributes = [\n",
    "        'Fecha', 'Tipo_Producto', 'Cantidad', 'Precio_Unitario', \n",
    "        'Descuento', 'Costo_Envio', 'Total'\n",
    "    ]\n",
    "    \n",
    "    # Start FactSales DF with attributes and original join columns\n",
    "    initial_columns = sales_attributes + join_columns\n",
    "    df_sales = df[initial_columns].copy()\n",
    "    \n",
    "    final_sales_columns = sales_attributes.copy()\n",
    "\n",
    "    # Merge Foreign Keys\n",
    "    for table, columns in dimension_tables.items():\n",
    "        df_dim = dimension_dfs[table]\n",
    "        fk_col = df_dim.columns[0] \n",
    "\n",
    "        # Left merge to get the Foreign Key ID\n",
    "        df_sales = pd.merge(\n",
    "            df_sales, \n",
    "            df_dim, \n",
    "            on=columns, \n",
    "            how='left'\n",
    "        )\n",
    "        \n",
    "        final_sales_columns.insert(0, fk_col)\n",
    "\n",
    "    # Finalize FactSales DF\n",
    "    df_sales = df_sales.drop(columns=join_columns, errors='ignore')\n",
    "    \n",
    "    # Insert Primary Key (ID_Venta)\n",
    "    df_sales.insert(0, 'ID_Venta', df_sales.reset_index(drop=True).index + 1)\n",
    "    final_sales_columns.insert(0, 'ID_Venta')\n",
    "    \n",
    "    # Select final columns in correct order\n",
    "    df_sales = df_sales[final_sales_columns].copy()\n",
    "\n",
    "    # Save the FactSales table\n",
    "    output_filename = os.path.join(OUTPUT_FOLDER, f\"seeder_FactVentas.csv\")\n",
    "    df_sales.to_csv(output_filename, index=False)\n",
    "    print(f\"  Saved: {output_filename} with {len(df_sales)} rows.\")\n",
    "    \n",
    "    print(\"\\nPhase 2: Normalization and Seeder Generation completed successfully.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during the Normalization phase: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
